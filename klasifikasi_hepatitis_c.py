# -*- coding: utf-8 -*-
"""UAS_Dean Farhan Lazuardi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EJZRMZaLeLroKVURUiJObs8pY8SLuvBd
"""

import numpy as np
import pandas as pd
import time

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_score
import plotly.express as px

"""# EDA"""

df = pd.read_csv('/content/HepatitisCdata.csv')
df.head()

df.rename(columns={'Unnamed: 0': 'X'}, inplace=True)
df.head()

df.info()

"""## Data Cleaning"""

#cek nilai null dalam setiap kolom di data set
print(df.isnull().sum())

#mengisi nilai null dengan mean dari kolom
mean_value = df['ALB'].mean()
df['ALB'].fillna(mean_value, inplace=True)

mean_value = df['ALP'].mean()
df['ALP'].fillna(mean_value, inplace=True)

mean_value = df['ALT'].mean()
df['ALT'].fillna(mean_value, inplace=True)

mean_value = df['CHOL'].mean()
df['CHOL'].fillna(mean_value, inplace=True)

mean_value = df['PROT'].mean()
df['PROT'].fillna(mean_value, inplace=True)

print(df.isnull().sum())

#cek duplikasi data
print(df.duplicated().sum())

"""## Data Visualization"""

df.describe()

# Statistik deskriptif untuk setiap kolom
print(df.describe())

# Perhitungan mean untuk setiap kolom
print(df.mean())

# Perhitungan median untuk setiap kolom
print(df.median())

# Perhitungan modus untuk setiap kolom
print(df.mode())

# Perhitungan persentil untuk setiap kolom
print(df.quantile([0.25, 0.50, 0.75]))

#Histogram Distribusi 'Category'
fig = px.bar(
    df.Category.value_counts(),
    color_discrete_sequence=['darkblue'],
    title='Distribusi dari Kolom Category',
)
fig.update_layout(
    xaxis_title = "Category",
    yaxis_title = "Frekuensi",
    title_x = 0.5,
    showlegend = False
)
fig.show()

#Histogram Distribusi 'Age'
age_counts = df.Age.value_counts()
fig = px.bar(age_counts, title="Age")
fig.update_layout(
    xaxis_title = "Age",
    yaxis_title = "Frekuensi",
    title_x = 0.5,
    showlegend = False
)
fig.show()

#Diagram pie 'Sex'
df.Sex.value_counts()
px.pie(df,names='Sex',title='Gender Overview',hole=0.8)

# Korelasi Pearson antara variabel numerik
correlation_matrix = df.corr(method='pearson')
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Histogram untuk setiap kolom numerik
df.hist(figsize=(10, 8))
plt.tight_layout()
plt.show()

"""## Data Transformation"""

df['Category'].value_counts()

"""label encoding"""

#memformat kolom Category
df['Category'] = df['Category'].str.split('=').str[1]
df['Category'] = df['Category'].str.split('s').str[0]

#label encoding kolom kategorikal (Category dan Sex)
label_encoder = LabelEncoder()
df['Category'] = label_encoder.fit_transform(df['Category'])
df['Sex'] = label_encoder.fit_transform(df['Sex'])

df.head()

X = df.drop('Category', axis=1)
y = df['Category']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

# Inisialisasi model Naive Bayes
model1 = GaussianNB()

start_time = time.time()
# Latih model Naive Bayes
model1.fit(X_train, y_train)

end_time = time.time()

y_pred = model1.predict(X_test)

print(classification_report(y_test,y_pred))
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)

training_time = end_time - start_time

print("Waktu pelatihan:", training_time, "detik")

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

# Inisialisasi model Random Forest
model2 = RandomForestClassifier()

start_time = time.time()
# Latih model Random Forest
model2.fit(X_train, y_train)

end_time = time.time()

y_pred = model2.predict(X_test)

print(classification_report(y_test,y_pred))

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)

training_time = end_time - start_time

print("Waktu pelatihan:", training_time, "detik")

"""# XGBOOST"""

import xgboost as xgb

model = xgb.XGBClassifier(n_estimators= 200 ,max_depth= 165)

#latih model
start_time = time.time()
model.fit(X_train, y_train)

end_time = time.time()

y_pred = model.predict(X_test)

print(classification_report(y_test,y_pred))

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)

training_time = end_time - start_time

print("Waktu pelatihan:", training_time, "detik")

"""Total Data yang digunakan: 615

Data Latih: 80%

Data Uji: 20%

1.  Naive Bayes
>*   Akurasi: 0.9349593495934959
>*   Waktu pelatihan: 0.007683515548706055 detik

2.   Random Forest
>* Akurasi: 0.959349593495935
>* Waktu pelatihan: 0.22917580604553223 detik

3.   XGBOOST
>* Akurasi: 0.983739837398374
>* Waktu pelatihan: 0.20133280754089355 detik

Jadi, algoritma yang paling bagus dipakai untuk dataset ini adalah XGBoost dengan akurasi paling tinggi dan waktu pelatihan yang sebentar, selama 0.2 detik.

"""